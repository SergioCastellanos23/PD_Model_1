# SERGIO ANTONIO CASTELLANOS TORRES
#### Consultor de riesgo - Ciencia de Datos | Credit Risk Analysis| Agribusiness

Este portafolio es creado con fines profesionales, medir mi capacidad como Consultor de riesgo y ciencia de datos. 
Estoy entusiasmado de aportar a este mundo del data science y al igual me encantar铆a tener retroalimentaci贸n de profesionales en el tema.

- Mail: sergio.castellanost23@gmail.com
- LinkedIn Profile: www.linkedin.com/in/sergio-antonio-castellanos-torres-828946126


## EDUCACIN 
- Agronegocios Internacionales | Universidad Veracruzana | 2021

## EXPERIENCIA 
 
### Consultor de riesgo y Ciencia de Datos 
- 3PI, LLC 路 ene. 2023 - actualidad 路

Desempe帽o el rol como Consultor de Riesgo y Ciencia de datos dentro de 3PI, LLC, en el 谩rea de Services (Project & Program Management) dentro de todas las fases de desarrollo de modelos.

- Apoyo al equipo de modelado en la limpieza, transformaci贸n y visualizaci贸n de datos con Pandas, Numpy, Matplotlib y Seaborn en la detecci贸n de valores at铆picos, imputaci贸n de datos y transformaci贸n o agrupaci贸n de variables categ贸ricas para la construcci贸n de modelos.
- Proporcionar insights con an谩lisis de estad铆stica descriptiva e inferencial en el proceso de selecci贸n de variables con un enfoque hacia la construcci贸n de un modelo parsimonioso y monot贸nico (Information Value, Correlaciones, Chi Squared Test, Variable Clustering) con OptimalBinning, Matplotlib, Statsmodels, VarClusHi.
- Construcci贸n de modelos de Credit Score (Logistic Regression, Decision Trees, Random Forest Classifier, XGB Classifier, AdaBoosClassifier) para incrementar la aprobaci贸n de solicitudes en el sector de cr茅dito, manteniendo el riesgo de incumplimiento y aumentando la rentabilidad.
- Consultar y capturar datos utilizando bases de datos como PostgreSQL para acceder a la informaci贸n necesaria en mis proyectos.


### CURSOS
- Intermediate Machine Learning | Kaggle
- Python
- PostgreSQL
- Excel
- PowerBI (Cursando)
- PySpark (Proximamente)


## PREDICT LIKELIHOOD

- El proyecto denominado "Predict Likelihood" fue un proyecto con datos limitados:
  
- Por ello, derivamos a tomar medidas muy creativas. Por ende, se tom贸 la decisi贸n de evaluar el rendimiento de las variables en cada modelo.
- Utilizamos Chi Square Test, Correlaci贸n (Spearman), Information Value, Random Forest, Decision Trees, XGBoost, entre otros.
- Para la detecci贸n de outliers utilizamos el rango intercuantil, sin embargo, ampliamos el umbral a 3.5 veces (valores extremos). A su vez Histogramas y graficos de cajas para analizar la distribuci贸n de los datos y considerar en si eliminar los valores atipicos detectados anteriormente.
- En conjunto analizamos los graficos de disperci贸n con linea de regresi贸n podemos observar la tendencia hacia DEFAULT, por ejemplo, DURATION, mientras mayor sea el termino, mayor la probabilidad de incumplimiento.
- En la variable AGE decidimos mantener solo la poblaci贸n menor a 67. Considerando a la poblaci贸n mayor a 67 como de "alto riesgo".
- Medimos el rendimiento de las variables en cada proceso (Chi Square, Correlaci贸n, Variable Clustering, Information Value), Forward, Backward y Stepwise Selection. Y posteriormente utilizando GridSearchCV para encontrar los mejores hiperparametros por cada modelo (Logistic Regression, Random Forest Classifier, XGB Classifier, Gradient Boosting Classifier, Decision Tree Classifier, AdaBoost Classifier y aprovechar al m谩ximo el proceso de selecci贸n de variables, adem谩s Lasso, Ridge y ElasticNet.
- Posteriormente, la selecci贸n del modelo se dividi贸 la muestra en Train y Test (70/30), utilizando los hiperparametros del paso de Variable Selection. Seleccionamos Logistic Regression.
- Transformamos los datos en ciertas variables (analizando los datos proporcionados por WOE y recrear monoticidad en los datos). 
- Al ejecutar el rendimiento de las variables en los modelos de ML se logr贸 apreciar cuales variables son fuertes predictores y su impacto constante en cada modelo, dichas variables fueron CHK_ACCT, DURATION. Los  dem谩s predictores se evaluaron con su rendimiento en los diferentes modelos y los diferentes Test como fue Information Value,  Chi Square, Correlaci贸n.
- El modelo se ejecut贸 mediante Regresi贸n Log铆stica, por su rendimiento en los 5 CV, un mean square error de los m谩s bajos dentro de la selecci贸n de modelos. Con un accuracy mayor a 75%, aceptable para la cantidad limitada de datos.
- Con los coeficientes se utiliz贸 la formula de regresi贸n logistica, multiplicando el coeficiente por el valor otorgado. Las variables que mayor repercuten en son CHK_ACCT, DURATION, USED_CAR y GUARANTOR.
- Se creo un Scorecard para fines de otorgamiento de cr茅dito a nuevos clientes con las mejores variables.
- Como validaci贸n del modelo se utilizo Gini, ROC Curve y KS, dando como resultado un 0.77 ROC AUC, KS= 48.59% y Gini de 0.55, considerandose aceptable en la predicci贸n.

## Credit Cars

- Un dataset con m谩s de 65,000 aplicantes para evaluar la probabilidad de morosidad e igual, aplicar un Scorecard:
 
- Notifiqu茅 algunas tendencias que fueron de alto impacto y que se deber铆an tomar en cuenta.
- Demasiados datos nulos y por ende, tomar la decisi贸n de imputar algunos datos.
- Transformamos variables por categorias, por ejemplo, 'STATE' fue dividida por zonas 'NORTH_STATES', 'MIDWEST_STATES', 'SOUTH_STATES', 'WEST_STATES' para simplificar nuestros datos, ya que al realizar nuestros analisis ser铆a complicado analizar su importancia.
- 
